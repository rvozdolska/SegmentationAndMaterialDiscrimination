{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import os\n",
    "from glob import glob\n",
    "from parse import parse\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import tensorflow.contrib.layers as lays\n",
    "import tensorflow.contrib.slim as slim\n",
    "import multiprocessing\n",
    "import itertools\n",
    "\n",
    "parsedlisttestSing=pd.read_csv('parsedlisttestSing.csv')\n",
    "parsedlisttrainSing=pd.read_csv('parsedlisttrainSing.csv')\n",
    "\n",
    "## TO DO FIX THE HARDOCODED IMAGE RESIZE Values\n",
    "def convert_to_image(path, system='sing', noise = True, varsM=['MeanDoCA','Mu', 'SmoothedNumPoCAs']):\n",
    "    df = pd.read_csv(path)\n",
    "    #df = df[df['z']>300]\n",
    "    nx = len(df.x.unique())\n",
    "    ny = len(df.y.unique())\n",
    "    nz = len(df.z.unique())\n",
    "    #df = df.sort_values(by=['z','y','x'])\n",
    "    #image = df[varsM].values.reshape(-1,nx,ny,nz)\n",
    "    ## normalize\n",
    "    #df[varsM] = (df[varsM] - df[varsM].min())/(df[varsM].max()-df[varsM].min())\n",
    "    df[varsM] = (df[varsM] - df[varsM].min())/(df[varsM].std())\n",
    "    if noise:\n",
    "        df[varsM] = df[varsM].apply(lambda x: x + 3*np.random.rand()/1)\n",
    "    image = df[varsM].to_records(index=False).reshape(nx,ny,nz)\n",
    "    image = np.array(image.tolist())\n",
    "    # reshape the volume so the deconvolutio would work\n",
    "    image = pad_along_axis(image,12,axis=0)\n",
    "    image = pad_along_axis(image,12,axis=2)\n",
    "    image = np.delete(image, 1, axis=1)\n",
    "    #df=df.loc[df['object_names'] <>''] #not sure about this\n",
    "    if system=='hmt_apg':\n",
    "        listofMaterials = ['ClutterA','ANFO','ClutterC','AN','Sugar', 'ClutterB','PCFO']\n",
    "    if system=='sing':\n",
    "        listofMaterials = ['Cigarettes', 'PPC', 'SodiumNitrate', 'WheatFlour', 'Textiles']\n",
    "    materialsPresent = df.columns.intersection(listofMaterials)\n",
    "    if len(materialsPresent) >0:\n",
    "        #df['AirOrNot'] = df[materialsPresent].apply(lambda row: 1 if sum(row)<=0.00 else 0, axis=1)\n",
    "        df['AirOrNot'] = df[materialsPresent].apply(lambda row: 1 if sum(row)<=0.0 else \n",
    "                                                    2 if sum(row)>0.0 and sum(row)<=0.2 else 0 , axis=1)\n",
    "        #df['AirOrNot'] = df[materialsPresent].apply(lambda row: 1 - sum(row), axis=1)\n",
    "    else:\n",
    "        df['AirOrNot'] = 1\n",
    "    nxn = 12\n",
    "    nyn = 24\n",
    "    nzn = 12\n",
    "    annotations = df['AirOrNot'].values.reshape(nx,ny,nz)\n",
    "    annotations = pad_along_axis(annotations,12,axis=0)\n",
    "    annotations = pad_along_axis(annotations,12,axis=2)\n",
    "    annotations = np.delete(annotations, 1, axis=1)\n",
    "    if noise:\n",
    "        positions = random.randint(-1000,1000)\n",
    "        image = np.roll(image, positions, axis=0)\n",
    "        annotations = np.roll(annotations, positions, axis=0)\n",
    "    return image, annotations\n",
    "\n",
    "def get_batches_fn(batch_size, image_path,x, y, z, shuffle = True, varsM=['MeanDoCA','Mu', 'SmoothedNumPoCAs'], \n",
    "                   trainflag='Train', system='sing', eval_phase=False, datasettype='ds'):\n",
    "    '''\n",
    "    Create batches, restricting the number of scans per run included. \n",
    "    sample was on 2 scans per run, changed to 10 \n",
    "    '''\n",
    "    if eval_phase==False:\n",
    "        m = image_path.groupby('run', group_keys=False).apply(lambda x: x.sample(min(len(x), 150)))\n",
    "        if shuffle:\n",
    "            shuffled = random.sample(m['filepath'].values, batch_size)\n",
    "        else:\n",
    "            shuffled = image_path['filepath'].values\n",
    "        images = []\n",
    "        labels = []\n",
    "        for im_path in shuffled:\n",
    "            if trainflag=='Train':\n",
    "                image, anno = convert_to_image(im_path,system, True, varsM)\n",
    "            else:\n",
    "                image, anno = convert_to_image(im_path,system,False, varsM)\n",
    "            images.append(image)\n",
    "            labels.append(anno)\n",
    "        labels = np.array(labels).reshape(batch_size, x*y*z)\n",
    "        images = np.array(images)\n",
    "        return tf.convert_to_tensor(images, dtype = tf.float32), tf.convert_to_tensor(labels, dtype = tf.float32)\n",
    "    if eval_phase ==True and datasettype=='vtp':\n",
    "        images = []\n",
    "        for im_path in image_path:\n",
    "            df = vtp_to_df(im_path)\n",
    "            nx = len(df.x.unique())\n",
    "            ny = len(df.y.unique())\n",
    "            nz = len(df.z.unique())\n",
    "            df[varsM] = (df[varsM] - df[varsM].min())/(df[varsM].max()-df[varsM].min())\n",
    "            image = df[varsM].to_records(index=False).reshape(nx,ny,nz)\n",
    "            image = np.array(image.tolist())\n",
    "            # reshape the volume so the deconvolution would work\n",
    "            image = pad_along_axis(image,12,axis=0)\n",
    "            image = pad_along_axis(image,12,axis=2)\n",
    "            image = np.delete(image, 0, axis=1)\n",
    "            images.append(image)\n",
    "        images = np.array(images)\n",
    "        return tf.convert_to_tensor(images, dtype = tf.float32)\n",
    "    if eval_phase ==True and datasettype=='ds':\n",
    "        images = []\n",
    "        labels = []\n",
    "        for im_path in image_path:\n",
    "            image, anno = convert_to_image(im_path,system,False, varsM)\n",
    "            images.append(image)\n",
    "            labels.append(anno)\n",
    "        labels = np.array(labels).reshape(1,12,24,12)\n",
    "        images = np.array(images)\n",
    "        return tf.convert_to_tensor(images, dtype = tf.float32), tf.convert_to_tensor(labels, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_along_axis(array, target_length, axis=0):\n",
    "    pad_size = target_length - array.shape[axis]\n",
    "    axis_nb = len(array.shape)\n",
    "    if pad_size < 0:\n",
    "        return a\n",
    "    npad = [(0, 0) for x in range(axis_nb)]\n",
    "    npad[axis] = (0, pad_size)\n",
    "    b = np.pad(array, pad_width=npad, mode='constant', constant_values=1)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 12, 24, 12, 8)\n",
      "('First Layer {}', (None, 6, 12, 6, 12))\n",
      "('Second Layer {}', (None, 3, 6, 3, 6))\n",
      "('First Deconv Layer {}', (None, 6, 12, 6, 6))\n",
      "('Second Deconv Layer {}', (None, 12, 24, 12, 12))\n",
      "('Final Net {}', (None, 3, 3456))\n",
      "('Shape of Labels {}', (None, 3456, 3))\n",
      "('Shape of Predictions {}', (None, 3456))\n"
     ]
    }
   ],
   "source": [
    "# build the graph\n",
    "x = 12#22\n",
    "y = 24#46\n",
    "z = 12 #9 #18 #22\n",
    "batch_size =50\n",
    "graph2 = tf.Graph()\n",
    "\n",
    "#varsM=['StoppedFracP', 'StoppedMean','FOM', 'Mu', 'box_p25', 'box_p50', 'dist_1_2']\n",
    "#varsM = ['FracMu', 'GeoMeanPThetaSquared', 'MikesFOM', 'Mu', 'box_p95', 'value_max_1', 'SmoothedNumPoCAs']\n",
    "#varsM = ['FracMu', 'GeoMeanPThetaSquared', 'Mu', 'box_p95', 'value_max_1']\n",
    "#varsM = ['GeoMeanPThetaSquared'constant, 'NumTracks', 'box_mean',  'box_p95', 'value_max_1', 'sum_max_1_5', 'NumStoppedTracks', 'box_std']\n",
    "#varsM = ['dist_1_2', 'dist_1_3', 'dist_2_3', 'n_2sigma', 'n_3sigma']\n",
    "#varsM = ['FracMu', 'box_p95','ScatteringRatio', 'n_3sigma','StoppedMeanP', 'SmoothedNumPoCAs', \n",
    "#         'StoppedThroughRatio', 'PoCAScat'] #<- TF7\n",
    "\n",
    "varsM = ['FracMu', 'box_p95','ScatteringRatio', 'n_3sigma','StoppedMeanP', 'SmoothedNumPoCAs', \n",
    "         'StoppedThroughRatio', 'PoCAScat']\n",
    "#varsM = ['box_p95','ScatteringRatio','GeoMeanTheta']\n",
    "\n",
    "\n",
    "# 'dist_1_3', 'dist_2_3', 'n_2sigma', 'sum_max_2_2', 'sum_max_3_2','sum_max_3_3', 'n_3sigma', 'FOMFrac', \n",
    "''' \"box_mean\", \"box_p25\", \"box_p50\", \"box_p75\" , \"box_p95\", \"box_std\", \"dist_1_2\", \n",
    "\"dist_1_3\", \"dist_2_3\", \"n_1sigma\", \"n_2sigma\" , \"n_3sigma\", \"sum_max_1_2\", \"sum_max_1_3\",\n",
    "\"sum_max_1_5\", \"sum_max_2_2\", \"sum_max_2_3\", \"sum_max_2_5\", \"sum_max_3_2\", \"sum_max_3_3\", \"sum_max_3_5\" , \n",
    "\"value_max_1\", \"value_max_2\", \"value_max_3\",  \"SmoothedNumPoCAs\", \"LogPTheta\", \"LogPThetaSquared\", \n",
    "\"GeoMeanPThetaSquared\", \"Sigma\", \"MeanTheta\", \"GeoMeanTheta\", \"NumTracks\", \"Mu\", \"PoCARate\", \n",
    "\"MeanDoCA\", \"GeoMeanFractionalScattering\" , \"MeanFractionalScattering\" , \n",
    "\"ScatteringRatio\", \"FracMu\", \"FracSigma\", \"FOMFrac\", \"FOM\", \"MikesFOM\", \"PoCAScat\", \"PoCALogScat\", \n",
    "\"NumStoppedTracks\", \"StoppedMean\", \"StoppedMeanP\", \n",
    "\"StoppedFracP\", \"StoppedThroughRatio\",\n",
    " \"x_max_1\", \"y_max_1\",  \"z_max_1\"] \n",
    " \n",
    "'''\n",
    "total_batch_train = len(parsedlisttrainSing)\n",
    "total_batch_test = len(parsedlisttestSing)\n",
    "with graph2.as_default():\n",
    "        # Placeholders\n",
    "    #batch_size = tf.placeholder(tf.float32, name='batch_size')    \n",
    "    input_images = tf.placeholder(tf.float32, shape=(None, x, y, z, (len(varsM))), name='input_images')\n",
    "    input_labels = tf.placeholder(tf.float32, shape=(None, x*y*z), name='input_labels')\n",
    "    phase = tf.placeholder(tf.bool, name='phase')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    eval_phase = tf.placeholder(tf.bool, name='eval_phase')\n",
    "\n",
    "    # Global step\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    datatopulltrain = parsedlisttrainSing[parsedlisttrainSing['secs']>=120]#parsedlisttrain.sample(total_batch_test)\n",
    "    datatopulltest = parsedlisttestSing[parsedlisttestSing['secs']>=120]#parsedlisttest.sample(total_batch_test)\n",
    "    ## Test and Train flag control if noise is added to the volume\n",
    "    eval_images, eval_labels = get_batches_fn(batch_size, datatopulltest, x, y, z, True, varsM, 'Test','sing', False,'ds')\n",
    "    train_images, train_labels = get_batches_fn(batch_size, datatopulltrain, x, y, z, True, varsM, 'Test', 'sing', False,'ds')\n",
    "    #eval_image_no_shuffle, eval_labels_no_shuffle = get_eval_im(datatopulltest[0:1], x, y, z, varsM)\n",
    "    \n",
    "    def shape_so(tensor):\n",
    "        s = tensor.get_shape()\n",
    "        return tuple([s[i].value for i in range(0, len(s))])\n",
    "    \n",
    "    def fcn_v3(inputs, x,y,z, phase):\n",
    "        # encoder\n",
    "        shape_to_code = shape_so(inputs)\n",
    "        print(shape_to_code)\n",
    "        #was 6\n",
    "        net = lays.conv3d(inputs, 6*len(varsM), [1, 1, 1], stride=1, padding='SAME', activation_fn=tf.nn.leaky_relu)\n",
    "        net = lays.conv3d(net, 6*len(varsM), [1, 1, 1], stride=1, padding='SAME', activation_fn=tf.nn.leaky_relu)\n",
    "        net = lays.conv3d(net, 6*len(varsM), [2,2,2], stride=2, padding='SAME', activation_fn=tf.nn.leaky_relu)        \n",
    "        net = tf.contrib.layers.batch_norm(net,center=True, scale=True, is_training=phase )\n",
    "        net = tf.nn.dropout(net, keep_prob)\n",
    "        shape_to_code = shape_so(net)\n",
    "        print('First Layer {}',shape_to_code)\n",
    "        # was 10\n",
    "        net = lays.conv3d(net, 3*len(varsM), [1, 1, 1], stride=1, padding='SAME', activation_fn=tf.nn.leaky_relu)\n",
    "        net = lays.conv3d(net, 3*len(varsM), [2,2,2], stride=2, padding='SAME', activation_fn=tf.nn.leaky_relu)\n",
    "        net = tf.contrib.layers.batch_norm(net,center=True, scale=True, is_training=phase )\n",
    "        net = tf.nn.dropout(net, keep_prob)\n",
    "        shape_to_code = shape_so(net)\n",
    "        print('Second Layer {}',shape_to_code)        \n",
    "        #x and z get from 3 to 2 if this is at stride 2, and then I cannot redo the convolution\n",
    "        #net = lays.conv3d(net, 1*len(varsM), [1, 1, 1], stride=1, padding='SAME', activation_fn=tf.nn.leaky_relu)\n",
    "        #net = lays.conv3d(net, 1*len(varsM), [2,2,2], stride=2, padding='SAME', activation_fn=tf.nn.leaky_relu) \n",
    "        #shape_to_code = shape_so(net)\n",
    "        #print('Third Layer {}',shape_to_code)\n",
    "\n",
    "        net = tf.layers.conv3d_transpose(net, 3*len(varsM), [1, 1, 1], strides=[1, 1, 1], padding='SAME', activation=tf.nn.leaky_relu)\n",
    "        net = tf.layers.conv3d_transpose(net, 3*len(varsM), [2,2,2], strides=[2,2,2], padding='SAME', activation=tf.nn.leaky_relu)\n",
    "        net = tf.contrib.layers.batch_norm(net,center=True, scale=True, is_training=phase )\n",
    "        net = tf.nn.dropout(net, keep_prob)\n",
    "\n",
    "        shape_to_code = shape_so(net)\n",
    "        print('First Deconv Layer {}',shape_to_code)\n",
    "        \n",
    "        net = tf.layers.conv3d_transpose(net, 6*len(varsM), [1, 1, 1], strides=[1, 1, 1], padding='SAME', activation=tf.nn.leaky_relu)\n",
    "        net = tf.layers.conv3d_transpose(net, 6*len(varsM), [1, 1, 1], strides=[1, 1, 1], padding='SAME', activation=tf.nn.leaky_relu)\n",
    "        net = tf.layers.conv3d_transpose(net, 6*len(varsM), [2,2,2], strides=[2, 2, 2], padding='SAME', activation=tf.nn.leaky_relu)\n",
    "        #    \n",
    "        net = tf.contrib.layers.batch_norm(net,center=True, scale=True, is_training=phase )\n",
    "        net = tf.nn.dropout(net, keep_prob)       \n",
    "        \n",
    "        shape_to_code = shape_so(net)\n",
    "        print('Second Deconv Layer {}',shape_to_code)\n",
    "        \n",
    "        #final layer\n",
    "        #net = lays.conv3d(net, 1*len(varsM), [1, 1, 1], stride=1, padding='SAME', activation_fn=tf.nn.leaky_relu)\n",
    "        net = tf.layers.conv3d_transpose(net, 3, [1, 1, 1], strides=[1, 1, 1], padding='SAME'\n",
    "                                         , activation=tf.nn.leaky_relu)\n",
    "     \n",
    "        #net = tf.contrib.layers.batch_norm(net,center=True, scale=True, is_training=phase )\n",
    " \n",
    "        # fully connected layers\n",
    "        #net = tf.layers.flatten(net)\n",
    "        net = tf.reshape(net, [-1,3,x*y*z])\n",
    "        shape_to_code = shape_so(net)\n",
    "        print('Final Net {}', shape_to_code)\n",
    "        return net     \n",
    "\n",
    "    fcn_outputs = tf.reshape(tensor=fcn_v3(input_images, x,y,z, phase),shape=(-1,x*y*z,3) )\n",
    "    predictionsOut = tf.argmax(fcn_outputs, dimension=2, name='fcn_outputs')\n",
    "    \n",
    "    labelsOH = tf.one_hot(indices=tf.cast(input_labels, tf.int32), depth=3)\n",
    "    print('Shape of Labels {}', shape_so(labelsOH))\n",
    "    print('Shape of Predictions {}', shape_so(predictionsOut))\n",
    "    loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=fcn_outputs, labels=labelsOH))\n",
    "    MIoU, mIoUop = tf.metrics.mean_iou(predictions=tf.cast(tf.round(predictionsOut),tf.int32),\n",
    "                                       labels=tf.cast(tf.round(input_labels),tf.int32),  num_classes=3,\n",
    "                                      name=\"mean_union\")\n",
    "    is_correct = tf.equal(tf.cast(tf.round(predictionsOut), tf.int64), tf.cast(input_labels, tf.int64))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "    # Training operations\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate=0.00001,#0.00001, #0.001\n",
    "                                               global_step=global_step, \n",
    "                                               #decay_steps=int(train_images.shape[0] / (2 * batch_size)), \n",
    "                                               decay_steps = 1000,\n",
    "                                               decay_rate=0.95, \n",
    "                                               staircase=True)\n",
    "    \n",
    "    #trainer = tf.train.RMSPropOptimizer(learning_rate)\n",
    "    trainer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_step = trainer.minimize(loss)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8, allow_growth=False)\n",
    "#config = tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=True)\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=multiprocessing.cpu_count(), \n",
    "                        inter_op_parallelism_threads=multiprocessing.cpu_count(), \n",
    "                        log_device_placement=True,\n",
    "                        gpu_options=gpu_options,\n",
    "                        allow_soft_placement=True, \n",
    "                        device_count = {'CPU' : 8, \n",
    "                                        'GPU' : 1}\n",
    "                       )\n",
    "        \n",
    "session2 = tf.InteractiveSession(graph=graph2, config=config)\n",
    "tf.global_variables_initializer().run()\n",
    "tf.local_variables_initializer().run()\n",
    "tf.train.start_queue_runners(sess=session2, start = True)\n",
    "with tf.control_dependencies([mIoUop]):\n",
    "    MIoU = tf.identity(MIoU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train loss: 218288.248 -Test loss: 210401.743 -Diff -7886.505 -Train FN 0.21 -Test FN 0.2 -Train MIoU 0.0 -Test MIou 0.071\n",
      "Epoch 2 - Train loss: 213463.678 -Test loss: 204908.145 -Diff -8555.533 -Train FN 0.22 -Test FN 0.203 -Train MIoU 0.0 -Test MIou 0.072\n",
      "Epoch 3 - Train loss: 209033.581 -Test loss: 199848.291 -Diff -9185.29 -Train FN 0.23 -Test FN 0.213 -Train MIoU 0.0 -Test MIou 0.073\n",
      "Epoch 4 - Train loss: 204856.985 -Test loss: 195087.595 -Diff -9769.39 -Train FN 0.24 -Test FN 0.23 -Train MIoU 0.0 -Test MIou 0.074\n",
      "Epoch 5 - Train loss: 200863.287 -Test loss: 190745.033 -Diff -10118.254 -Train FN 0.25 -Test FN 0.254 -Train MIoU 0.0 -Test MIou 0.077\n",
      "Epoch 6 - Train loss: 197130.432 -Test loss: 186843.236 -Diff -10287.196 -Train FN 0.27 -Test FN 0.281 -Train MIoU 0.0 -Test MIou 0.08\n",
      "Epoch 7 - Train loss: 193634.134 -Test loss: 183287.297 -Diff -10346.837 -Train FN 0.29 -Test FN 0.319 -Train MIoU 0.0 -Test MIou 0.084\n",
      "Epoch 8 - Train loss: 190480.568 -Test loss: 179995.426 -Diff -10485.142 -Train FN 0.32 -Test FN 0.376 -Train MIoU 0.0 -Test MIou 0.089\n",
      "Epoch 9 - Train loss: 187328.928 -Test loss: 176813.022 -Diff -10515.906 -Train FN 0.36 -Test FN 0.424 -Train MIoU 0.0 -Test MIou 0.095\n",
      "Epoch 10 - Train loss: 184220.448 -Test loss: 173574.848 -Diff -10645.6 -Train FN 0.39 -Test FN 0.468 -Train MIoU 0.0 -Test MIou 0.102\n",
      "Epoch 11 - Train loss: 181192.271 -Test loss: 170228.789 -Diff -10963.482 -Train FN 0.42 -Test FN 0.504 -Train MIoU 0.0 -Test MIou 0.108\n",
      "Epoch 12 - Train loss: 178069.188 -Test loss: 166710.244 -Diff -11358.944 -Train FN 0.45 -Test FN 0.524 -Train MIoU 0.0 -Test MIou 0.115\n",
      "Epoch 13 - Train loss: 174956.349 -Test loss: 163104.098 -Diff -11852.251 -Train FN 0.48 -Test FN 0.532 -Train MIoU 0.0 -Test MIou 0.12\n",
      "Epoch 14 - Train loss: 171832.275 -Test loss: 159617.513 -Diff -12214.762 -Train FN 0.5 -Test FN 0.534 -Train MIoU 0.0 -Test MIou 0.125\n",
      "Epoch 15 - Train loss: 168702.152 -Test loss: 156390.318 -Diff -12311.834 -Train FN 0.51 -Test FN 0.534 -Train MIoU 0.0 -Test MIou 0.129\n",
      "Epoch 16 - Train loss: 165815.705 -Test loss: 153503.044 -Diff -12312.661 -Train FN 0.52 -Test FN 0.533 -Train MIoU 0.0 -Test MIou 0.133\n",
      "Epoch 17 - Train loss: 163112.587 -Test loss: 150954.907 -Diff -12157.68 -Train FN 0.53 -Test FN 0.533 -Train MIoU 0.0 -Test MIou 0.136\n",
      "Epoch 18 - Train loss: 160703.78 -Test loss: 148713.828 -Diff -11989.952 -Train FN 0.54 -Test FN 0.533 -Train MIoU 0.0 -Test MIou 0.139\n",
      "Epoch 19 - Train loss: 158542.932 -Test loss: 146778.381 -Diff -11764.551 -Train FN 0.55 -Test FN 0.536 -Train MIoU 0.0 -Test MIou 0.141\n",
      "Epoch 20 - Train loss: 156433.278 -Test loss: 145017.907 -Diff -11415.371 -Train FN 0.55 -Test FN 0.543 -Train MIoU 0.0 -Test MIou 0.143\n",
      "Epoch 21 - Train loss: 154569.581 -Test loss: 143315.783 -Diff -11253.798 -Train FN 0.56 -Test FN 0.564 -Train MIoU 0.0 -Test MIou 0.146\n",
      "Epoch 22 - Train loss: 152678.014 -Test loss: 141284.5 -Diff -11393.514 -Train FN 0.57 -Test FN 0.591 -Train MIoU 0.0 -Test MIou 0.148\n",
      "Epoch 23 - Train loss: 150739.785 -Test loss: 138882.61 -Diff -11857.175 -Train FN 0.58 -Test FN 0.603 -Train MIoU 0.0 -Test MIou 0.151\n",
      "Epoch 24 - Train loss: 148803.79 -Test loss: 136467.667 -Diff -12336.123 -Train FN 0.59 -Test FN 0.609 -Train MIoU 0.0 -Test MIou 0.153\n",
      "Epoch 25 - Train loss: 146757.518 -Test loss: 134163.605 -Diff -12593.913 -Train FN 0.6 -Test FN 0.614 -Train MIoU 0.0 -Test MIou 0.156\n",
      "Epoch 26 - Train loss: 144860.195 -Test loss: 132105.944 -Diff -12754.251 -Train FN 0.61 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.158\n",
      "Epoch 27 - Train loss: 143037.887 -Test loss: 130341.191 -Diff -12696.696 -Train FN 0.61 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.16\n",
      "Epoch 28 - Train loss: 141364.423 -Test loss: 128839.126 -Diff -12525.297 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.162\n",
      "Epoch 29 - Train loss: 139917.858 -Test loss: 127534.123 -Diff -12383.735 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.164\n",
      "Epoch 30 - Train loss: 138605.686 -Test loss: 126335.448 -Diff -12270.238 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.166\n",
      "Epoch 31 - Train loss: 137303.486 -Test loss: 125235.95 -Diff -12067.536 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.167\n",
      "Epoch 32 - Train loss: 136185.134 -Test loss: 124266.812 -Diff -11918.322 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.169\n",
      "Epoch 33 - Train loss: 135174.309 -Test loss: 123406.208 -Diff -11768.101 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.17\n",
      "Epoch 34 - Train loss: 134198.562 -Test loss: 122601.303 -Diff -11597.259 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.171\n",
      "Epoch 35 - Train loss: 133293.119 -Test loss: 121866.796 -Diff -11426.323 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.173\n",
      "Epoch 36 - Train loss: 132443.244 -Test loss: 121180.617 -Diff -11262.627 -Train FN 0.62 -Test FN 0.618 -Train MIoU 0.0 -Test MIou 0.174\n",
      "Epoch 37 - Train loss: 131625.785 -Test loss: 120527.062 -Diff -11098.723 -Train FN 0.62 -Test FN 0.618 -Train MIoU 0.0 -Test MIou 0.175\n",
      "Epoch 38 - Train loss: 130887.634 -Test loss: 119900.79 -Diff -10986.844 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.176\n",
      "Epoch 39 - Train loss: 130122.671 -Test loss: 119302.002 -Diff -10820.669 -Train FN 0.62 -Test FN 0.618 -Train MIoU 0.0 -Test MIou 0.177\n",
      "Epoch 40 - Train loss: 129440.72 -Test loss: 118701.29 -Diff -10739.43 -Train FN 0.62 -Test FN 0.618 -Train MIoU 0.0 -Test MIou 0.178\n",
      "Epoch 41 - Train loss: 128728.746 -Test loss: 118097.039 -Diff -10631.707 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.179\n",
      "Epoch 42 - Train loss: 128085.18 -Test loss: 117524.359 -Diff -10560.821 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.18\n",
      "Epoch 43 - Train loss: 127390.522 -Test loss: 116971.166 -Diff -10419.356 -Train FN 0.62 -Test FN 0.618 -Train MIoU 0.0 -Test MIou 0.18\n",
      "Epoch 44 - Train loss: 126771.749 -Test loss: 116425.285 -Diff -10346.464 -Train FN 0.62 -Test FN 0.618 -Train MIoU 0.0 -Test MIou 0.181\n",
      "Epoch 45 - Train loss: 126148.763 -Test loss: 115894.52 -Diff -10254.243 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.182\n",
      "Epoch 46 - Train loss: 125556.825 -Test loss: 115374.901 -Diff -10181.924 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.183\n",
      "Epoch 47 - Train loss: 124929.226 -Test loss: 114850.752 -Diff -10078.474 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.183\n",
      "Epoch 48 - Train loss: 124334.214 -Test loss: 114322.835 -Diff -10011.379 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.184\n",
      "Epoch 49 - Train loss: 123772.105 -Test loss: 113789.253 -Diff -9982.852 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.184\n",
      "Epoch 50 - Train loss: 123133.65 -Test loss: 113262.573 -Diff -9871.077 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.185\n",
      "Epoch 51 - Train loss: 122590.353 -Test loss: 112735.247 -Diff -9855.106 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.186\n",
      "Epoch 52 - Train loss: 121978.129 -Test loss: 112191.98 -Diff -9786.149 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.186\n",
      "Epoch 53 - Train loss: 121392.842 -Test loss: 111653.173 -Diff -9739.669 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.187\n",
      "Epoch 54 - Train loss: 120811.926 -Test loss: 111116.033 -Diff -9695.893 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.187\n",
      "Epoch 55 - Train loss: 120231.272 -Test loss: 110561.208 -Diff -9670.064 -Train FN 0.62 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.188\n",
      "Epoch 56 - Train loss: 119633.1 -Test loss: 110004.902 -Diff -9628.198 -Train FN 0.63 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.188\n",
      "Epoch 57 - Train loss: 119044.879 -Test loss: 109444.538 -Diff -9600.341 -Train FN 0.63 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.189\n",
      "Epoch 58 - Train loss: 118452.292 -Test loss: 108883.332 -Diff -9568.96 -Train FN 0.63 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.189\n",
      "Epoch 59 - Train loss: 117847.773 -Test loss: 108312.103 -Diff -9535.67 -Train FN 0.63 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.189\n",
      "Epoch 60 - Train loss: 117247.195 -Test loss: 107737.949 -Diff -9509.246 -Train FN 0.63 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.19\n",
      "Epoch 61 - Train loss: 116649.861 -Test loss: 107163.625 -Diff -9486.236 -Train FN 0.64 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 - Train loss: 116037.047 -Test loss: 106580.54 -Diff -9456.507 -Train FN 0.64 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.19\n",
      "Epoch 63 - Train loss: 115467.099 -Test loss: 105991.73 -Diff -9475.369 -Train FN 0.64 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.191\n",
      "Epoch 64 - Train loss: 114846.944 -Test loss: 105390.264 -Diff -9456.68 -Train FN 0.64 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.191\n",
      "Epoch 65 - Train loss: 114235.799 -Test loss: 104781.659 -Diff -9454.14 -Train FN 0.65 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.192\n",
      "Epoch 66 - Train loss: 113639.847 -Test loss: 104165.546 -Diff -9474.301 -Train FN 0.65 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.192\n",
      "Epoch 67 - Train loss: 113006.172 -Test loss: 103548.1 -Diff -9458.072 -Train FN 0.66 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.192\n",
      "Epoch 68 - Train loss: 112359.667 -Test loss: 102936.509 -Diff -9423.158 -Train FN 0.67 -Test FN 0.616 -Train MIoU 0.0 -Test MIou 0.192\n",
      "Epoch 69 - Train loss: 111631.172 -Test loss: 102330.874 -Diff -9300.298 -Train FN 0.68 -Test FN 0.617 -Train MIoU 0.0 -Test MIou 0.193\n",
      "Epoch 70 - Train loss: 110677.871 -Test loss: 101743.064 -Diff -8934.807 -Train FN 0.7 -Test FN 0.62 -Train MIoU 0.0 -Test MIou 0.193\n",
      "Epoch 71 - Train loss: 108897.644 -Test loss: 101237.051 -Diff -7660.593 -Train FN 0.72 -Test FN 0.734 -Train MIoU 0.0 -Test MIou 0.194\n",
      "Epoch 72 - Train loss: 106562.685 -Test loss: 99699.247 -Diff -6863.438 -Train FN 0.73 -Test FN 0.737 -Train MIoU 0.0 -Test MIou 0.195\n",
      "Epoch 73 - Train loss: 105020.123 -Test loss: 95787.047 -Diff -9233.076 -Train FN 0.74 -Test FN 0.737 -Train MIoU 0.0 -Test MIou 0.195\n",
      "Epoch 74 - Train loss: 103941.578 -Test loss: 93157.372 -Diff -10784.206 -Train FN 0.74 -Test FN 0.737 -Train MIoU 0.0 -Test MIou 0.196\n",
      "Epoch 75 - Train loss: 102988.129 -Test loss: 91046.973 -Diff -11941.156 -Train FN 0.75 -Test FN 0.736 -Train MIoU 0.0 -Test MIou 0.197\n",
      "Epoch 76 - Train loss: 101999.207 -Test loss: 89122.014 -Diff -12877.193 -Train FN 0.76 -Test FN 0.736 -Train MIoU 0.0 -Test MIou 0.198\n",
      "Epoch 77 - Train loss: 100924.677 -Test loss: 87306.376 -Diff -13618.301 -Train FN 0.77 -Test FN 0.736 -Train MIoU 0.0 -Test MIou 0.198\n",
      "Epoch 78 - Train loss: 99689.183 -Test loss: 85672.725 -Diff -14016.458 -Train FN 0.77 -Test FN 0.735 -Train MIoU 0.0 -Test MIou 0.199\n",
      "Epoch 79 - Train loss: 98310.206 -Test loss: 84235.605 -Diff -14074.601 -Train FN 0.78 -Test FN 0.735 -Train MIoU 0.0 -Test MIou 0.2\n",
      "Epoch 80 - Train loss: 97009.358 -Test loss: 83070.211 -Diff -13939.147 -Train FN 0.78 -Test FN 0.734 -Train MIoU 0.0 -Test MIou 0.2\n",
      "Epoch 81 - Train loss: 95858.192 -Test loss: 82078.25 -Diff -13779.942 -Train FN 0.79 -Test FN 0.734 -Train MIoU 0.0 -Test MIou 0.201\n",
      "Epoch 82 - Train loss: 94808.274 -Test loss: 81133.329 -Diff -13674.945 -Train FN 0.8 -Test FN 0.734 -Train MIoU 0.0 -Test MIou 0.202\n",
      "Epoch 83 - Train loss: 93792.292 -Test loss: 80204.921 -Diff -13587.371 -Train FN 0.8 -Test FN 0.733 -Train MIoU 0.0 -Test MIou 0.202\n",
      "Epoch 84 - Train loss: 92879.956 -Test loss: 79322.368 -Diff -13557.588 -Train FN 0.81 -Test FN 0.733 -Train MIoU 0.0 -Test MIou 0.203\n",
      "Epoch 85 - Train loss: 91983.414 -Test loss: 78464.902 -Diff -13518.512 -Train FN 0.81 -Test FN 0.733 -Train MIoU 0.0 -Test MIou 0.204\n",
      "Epoch 86 - Train loss: 91093.77 -Test loss: 77657.257 -Diff -13436.513 -Train FN 0.82 -Test FN 0.802 -Train MIoU 0.0 -Test MIou 0.204\n",
      "Epoch 87 - Train loss: 90180.289 -Test loss: 76864.305 -Diff -13315.984 -Train FN 0.82 -Test FN 0.845 -Train MIoU 0.0 -Test MIou 0.205\n",
      "Epoch 88 - Train loss: 89340.172 -Test loss: 76077.343 -Diff -13262.829 -Train FN 0.83 -Test FN 0.847 -Train MIoU 0.0 -Test MIou 0.206\n",
      "Epoch 89 - Train loss: 88513.415 -Test loss: 75282.855 -Diff -13230.56 -Train FN 0.84 -Test FN 0.848 -Train MIoU 0.0 -Test MIou 0.207\n",
      "Epoch 90 - Train loss: 87705.088 -Test loss: 74498.544 -Diff -13206.544 -Train FN 0.84 -Test FN 0.849 -Train MIoU 0.0 -Test MIou 0.208\n",
      "Epoch 91 - Train loss: 86907.616 -Test loss: 73706.872 -Diff -13200.744 -Train FN 0.85 -Test FN 0.85 -Train MIoU 0.0 -Test MIou 0.209\n",
      "Epoch 92 - Train loss: 86095.309 -Test loss: 72907.673 -Diff -13187.636 -Train FN 0.86 -Test FN 0.856 -Train MIoU 0.0 -Test MIou 0.21\n",
      "Epoch 93 - Train loss: 85278.464 -Test loss: 72095.335 -Diff -13183.129 -Train FN 0.86 -Test FN 0.937 -Train MIoU 0.0 -Test MIou 0.211\n",
      "Epoch 94 - Train loss: 84497.216 -Test loss: 71288.76 -Diff -13208.456 -Train FN 0.87 -Test FN 0.964 -Train MIoU 0.0 -Test MIou 0.213\n",
      "Epoch 95 - Train loss: 83675.082 -Test loss: 70471.535 -Diff -13203.547 -Train FN 0.88 -Test FN 0.966 -Train MIoU 0.0 -Test MIou 0.214\n",
      "Epoch 96 - Train loss: 82890.208 -Test loss: 69660.004 -Diff -13230.204 -Train FN 0.89 -Test FN 0.966 -Train MIoU 0.0 -Test MIou 0.215\n",
      "Epoch 97 - Train loss: 82035.833 -Test loss: 68851.074 -Diff -13184.759 -Train FN 0.89 -Test FN 0.966 -Train MIoU 0.0 -Test MIou 0.217\n",
      "Epoch 98 - Train loss: 81228.41 -Test loss: 68045.051 -Diff -13183.359 -Train FN 0.9 -Test FN 0.967 -Train MIoU 0.0 -Test MIou 0.218\n",
      "Epoch 99 - Train loss: 80368.75 -Test loss: 67253.244 -Diff -13115.506 -Train FN 0.91 -Test FN 0.967 -Train MIoU 0.0 -Test MIou 0.219\n",
      "Epoch 100 - Train loss: 79477.623 -Test loss: 66483.199 -Diff -12994.424 -Train FN 0.92 -Test FN 0.966 -Train MIoU 0.0 -Test MIou 0.221\n",
      "Epoch 101 - Train loss: 77748.559 -Test loss: 65656.162 -Diff -12092.397 -Train FN 0.93 -Test FN 0.966 -Train MIoU 0.0 -Test MIou 0.222\n",
      "Epoch 102 - Train loss: 74262.365 -Test loss: 61004.23 -Diff -13258.135 -Train FN 0.95 -Test FN 0.963 -Train MIoU 0.0 -Test MIou 0.223\n",
      "Epoch 103 - Train loss: 70945.036 -Test loss: 58324.066 -Diff -12620.97 -Train FN 0.95 -Test FN 0.96 -Train MIoU 0.0 -Test MIou 0.225\n",
      "Epoch 104 - Train loss: 67175.316 -Test loss: 53805.698 -Diff -13369.618 -Train FN 0.95 -Test FN 0.957 -Train MIoU 0.0 -Test MIou 0.226\n",
      "Epoch 105 - Train loss: 64846.004 -Test loss: 51690.962 -Diff -13155.042 -Train FN 0.95 -Test FN 0.956 -Train MIoU 0.0 -Test MIou 0.227\n",
      "Epoch 106 - Train loss: 63168.095 -Test loss: 50326.375 -Diff -12841.72 -Train FN 0.95 -Test FN 0.956 -Train MIoU 0.0 -Test MIou 0.228\n",
      "Epoch 107 - Train loss: 61821.166 -Test loss: 49204.993 -Diff -12616.173 -Train FN 0.95 -Test FN 0.955 -Train MIoU 0.0 -Test MIou 0.23\n",
      "Epoch 108 - Train loss: 60628.583 -Test loss: 48209.887 -Diff -12418.696 -Train FN 0.95 -Test FN 0.955 -Train MIoU 0.0 -Test MIou 0.231\n",
      "Epoch 109 - Train loss: 59555.531 -Test loss: 47272.806 -Diff -12282.725 -Train FN 0.95 -Test FN 0.955 -Train MIoU 0.0 -Test MIou 0.232\n",
      "Epoch 110 - Train loss: 58630.637 -Test loss: 46382.833 -Diff -12247.804 -Train FN 0.95 -Test FN 0.955 -Train MIoU 0.0 -Test MIou 0.233\n",
      "Epoch 111 - Train loss: 57734.864 -Test loss: 45525.742 -Diff -12209.122 -Train FN 0.95 -Test FN 0.956 -Train MIoU 0.0 -Test MIou 0.235\n",
      "Epoch 112 - Train loss: 56852.907 -Test loss: 44695.844 -Diff -12157.063 -Train FN 0.95 -Test FN 0.956 -Train MIoU 0.0 -Test MIou 0.236\n",
      "Epoch 113 - Train loss: 56008.305 -Test loss: 43876.973 -Diff -12131.332 -Train FN 0.95 -Test FN 0.957 -Train MIoU 0.0 -Test MIou 0.237\n",
      "Epoch 114 - Train loss: 55172.54 -Test loss: 43057.82 -Diff -12114.72 -Train FN 0.95 -Test FN 0.958 -Train MIoU 0.0 -Test MIou 0.238\n",
      "Epoch 115 - Train loss: 54437.228 -Test loss: 42259.063 -Diff -12178.165 -Train FN 0.95 -Test FN 0.959 -Train MIoU 0.0 -Test MIou 0.239\n",
      "Epoch 116 - Train loss: 53663.718 -Test loss: 41473.048 -Diff -12190.67 -Train FN 0.96 -Test FN 0.96 -Train MIoU 0.0 -Test MIou 0.24\n",
      "Epoch 117 - Train loss: 52934.304 -Test loss: 40708.729 -Diff -12225.575 -Train FN 0.96 -Test FN 0.96 -Train MIoU 0.0 -Test MIou 0.242\n",
      "Epoch 118 - Train loss: 52166.882 -Test loss: 39965.321 -Diff -12201.561 -Train FN 0.96 -Test FN 0.961 -Train MIoU 0.0 -Test MIou 0.243\n",
      "Epoch 119 - Train loss: 51480.995 -Test loss: 39236.589 -Diff -12244.406 -Train FN 0.96 -Test FN 0.962 -Train MIoU 0.0 -Test MIou 0.244\n",
      "Epoch 120 - Train loss: 50766.936 -Test loss: 38521.7 -Diff -12245.236 -Train FN 0.96 -Test FN 0.963 -Train MIoU 0.0 -Test MIou 0.245\n",
      "Epoch 121 - Train loss: 50111.06 -Test loss: 37837.599 -Diff -12273.461 -Train FN 0.96 -Test FN 0.963 -Train MIoU 0.0 -Test MIou 0.246\n",
      "Epoch 122 - Train loss: 49433.301 -Test loss: 37167.79 -Diff -12265.511 -Train FN 0.96 -Test FN 0.964 -Train MIoU 0.0 -Test MIou 0.247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 - Train loss: 48812.47 -Test loss: 36520.826 -Diff -12291.644 -Train FN 0.96 -Test FN 0.965 -Train MIoU 0.0 -Test MIou 0.248\n",
      "Epoch 124 - Train loss: 48173.022 -Test loss: 35884.517 -Diff -12288.505 -Train FN 0.96 -Test FN 0.965 -Train MIoU 0.0 -Test MIou 0.249\n",
      "Epoch 125 - Train loss: 47558.596 -Test loss: 35284.328 -Diff -12274.268 -Train FN 0.96 -Test FN 0.966 -Train MIoU 0.0 -Test MIou 0.25\n",
      "Epoch 126 - Train loss: 46966.708 -Test loss: 34692.993 -Diff -12273.715 -Train FN 0.96 -Test FN 0.966 -Train MIoU 0.0 -Test MIou 0.251\n",
      "Epoch 127 - Train loss: 46333.417 -Test loss: 34100.465 -Diff -12232.952 -Train FN 0.96 -Test FN 0.967 -Train MIoU 0.0 -Test MIou 0.252\n",
      "Epoch 128 - Train loss: 45742.781 -Test loss: 33537.761 -Diff -12205.02 -Train FN 0.96 -Test FN 0.968 -Train MIoU 0.0 -Test MIou 0.253\n",
      "Epoch 129 - Train loss: 45178.159 -Test loss: 32985.622 -Diff -12192.537 -Train FN 0.96 -Test FN 0.968 -Train MIoU 0.0 -Test MIou 0.254\n",
      "Epoch 130 - Train loss: 44634.413 -Test loss: 32446.951 -Diff -12187.462 -Train FN 0.96 -Test FN 0.969 -Train MIoU 0.0 -Test MIou 0.255\n",
      "Epoch 131 - Train loss: 44105.449 -Test loss: 31908.959 -Diff -12196.49 -Train FN 0.96 -Test FN 0.969 -Train MIoU 0.0 -Test MIou 0.256\n",
      "Epoch 132 - Train loss: 43509.962 -Test loss: 31388.818 -Diff -12121.144 -Train FN 0.96 -Test FN 0.969 -Train MIoU 0.0 -Test MIou 0.256\n",
      "Epoch 133 - Train loss: 43041.433 -Test loss: 30867.615 -Diff -12173.818 -Train FN 0.96 -Test FN 0.97 -Train MIoU 0.0 -Test MIou 0.257\n",
      "Epoch 134 - Train loss: 42484.748 -Test loss: 30358.991 -Diff -12125.757 -Train FN 0.96 -Test FN 0.97 -Train MIoU 0.0 -Test MIou 0.258\n",
      "Epoch 135 - Train loss: 41992.607 -Test loss: 29878.165 -Diff -12114.442 -Train FN 0.96 -Test FN 0.971 -Train MIoU 0.0 -Test MIou 0.259\n",
      "Epoch 136 - Train loss: 41495.301 -Test loss: 29383.632 -Diff -12111.669 -Train FN 0.96 -Test FN 0.971 -Train MIoU 0.0 -Test MIou 0.26\n",
      "Epoch 137 - Train loss: 41005.228 -Test loss: 28902.439 -Diff -12102.789 -Train FN 0.96 -Test FN 0.972 -Train MIoU 0.0 -Test MIou 0.261\n",
      "Epoch 138 - Train loss: 40490.997 -Test loss: 28441.548 -Diff -12049.449 -Train FN 0.96 -Test FN 0.972 -Train MIoU 0.0 -Test MIou 0.262\n",
      "Epoch 139 - Train loss: 40102.571 -Test loss: 27994.683 -Diff -12107.888 -Train FN 0.96 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.263\n",
      "Epoch 140 - Train loss: 39569.116 -Test loss: 27546.844 -Diff -12022.272 -Train FN 0.96 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.263\n",
      "Epoch 141 - Train loss: 39124.561 -Test loss: 27109.768 -Diff -12014.793 -Train FN 0.96 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.264\n",
      "Epoch 142 - Train loss: 38693.378 -Test loss: 26696.492 -Diff -11996.886 -Train FN 0.96 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.265\n",
      "Epoch 143 - Train loss: 38256.364 -Test loss: 26280.17 -Diff -11976.194 -Train FN 0.96 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.266\n",
      "Epoch 144 - Train loss: 37831.026 -Test loss: 25877.461 -Diff -11953.565 -Train FN 0.96 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.267\n",
      "Epoch 145 - Train loss: 37370.996 -Test loss: 25471.361 -Diff -11899.635 -Train FN 0.96 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.267\n",
      "Epoch 146 - Train loss: 37045.555 -Test loss: 25083.309 -Diff -11962.246 -Train FN 0.96 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.268\n",
      "Epoch 147 - Train loss: 36584.464 -Test loss: 24705.614 -Diff -11878.85 -Train FN 0.96 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.269\n",
      "Epoch 148 - Train loss: 36226.475 -Test loss: 24319.525 -Diff -11906.95 -Train FN 0.96 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.27\n",
      "Epoch 149 - Train loss: 35836.016 -Test loss: 23971.354 -Diff -11864.662 -Train FN 0.96 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.27\n",
      "Epoch 150 - Train loss: 35422.154 -Test loss: 23615.266 -Diff -11806.888 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.271\n",
      "Epoch 151 - Train loss: 35057.305 -Test loss: 23274.233 -Diff -11783.072 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.272\n",
      "Epoch 152 - Train loss: 34696.516 -Test loss: 22949.693 -Diff -11746.823 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.273\n",
      "Epoch 153 - Train loss: 34348.899 -Test loss: 22605.948 -Diff -11742.951 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.273\n",
      "Epoch 154 - Train loss: 33987.944 -Test loss: 22292.264 -Diff -11695.68 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.274\n",
      "Epoch 155 - Train loss: 33666.429 -Test loss: 21971.938 -Diff -11694.491 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.275\n",
      "Epoch 156 - Train loss: 33358.509 -Test loss: 21674.71 -Diff -11683.799 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.276\n",
      "Epoch 157 - Train loss: 33001.911 -Test loss: 21379.885 -Diff -11622.026 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.276\n",
      "Epoch 158 - Train loss: 32705.821 -Test loss: 21084.417 -Diff -11621.404 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.277\n",
      "Epoch 159 - Train loss: 32406.209 -Test loss: 20804.489 -Diff -11601.72 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.278\n",
      "Epoch 160 - Train loss: 32047.976 -Test loss: 20533.127 -Diff -11514.849 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.278\n",
      "Epoch 161 - Train loss: 31778.547 -Test loss: 20257.939 -Diff -11520.608 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.279\n",
      "Epoch 162 - Train loss: 31481.14 -Test loss: 20007.681 -Diff -11473.459 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.28\n",
      "Epoch 163 - Train loss: 31208.258 -Test loss: 19748.101 -Diff -11460.157 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.28\n",
      "Epoch 164 - Train loss: 30925.601 -Test loss: 19505.112 -Diff -11420.489 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.281\n",
      "Epoch 165 - Train loss: 30682.429 -Test loss: 19256.574 -Diff -11425.855 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.282\n",
      "Epoch 166 - Train loss: 30392.246 -Test loss: 19038.408 -Diff -11353.838 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.282\n",
      "Epoch 167 - Train loss: 30147.529 -Test loss: 18795.429 -Diff -11352.1 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.283\n",
      "Epoch 168 - Train loss: 29893.787 -Test loss: 18542.613 -Diff -11351.174 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.284\n",
      "Epoch 169 - Train loss: 29656.731 -Test loss: 18353.491 -Diff -11303.24 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.284\n",
      "Epoch 170 - Train loss: 29401.639 -Test loss: 18143.177 -Diff -11258.462 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.285\n",
      "Epoch 171 - Train loss: 29155.119 -Test loss: 17938.465 -Diff -11216.654 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.286\n",
      "Epoch 172 - Train loss: 28927.263 -Test loss: 17751.044 -Diff -11176.219 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.286\n",
      "Epoch 173 - Train loss: 28709.06 -Test loss: 17544.584 -Diff -11164.476 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.287\n",
      "Epoch 174 - Train loss: 28475.761 -Test loss: 17368.595 -Diff -11107.166 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.287\n",
      "Epoch 175 - Train loss: 28283.421 -Test loss: 17173.63 -Diff -11109.791 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.288\n",
      "Epoch 176 - Train loss: 28068.828 -Test loss: 17016.165 -Diff -11052.663 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.289\n",
      "Epoch 177 - Train loss: 27851.31 -Test loss: 16841.238 -Diff -11010.072 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.289\n",
      "Epoch 178 - Train loss: 27633.249 -Test loss: 16661.272 -Diff -10971.977 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.29\n",
      "Epoch 179 - Train loss: 27444.953 -Test loss: 16509.106 -Diff -10935.847 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.29\n",
      "Epoch 180 - Train loss: 27262.306 -Test loss: 16351.915 -Diff -10910.391 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.291\n",
      "Epoch 181 - Train loss: 27081.312 -Test loss: 16188.006 -Diff -10893.306 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.291\n",
      "Epoch 182 - Train loss: 26881.705 -Test loss: 16044.646 -Diff -10837.059 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.292\n",
      "Epoch 183 - Train loss: 26714.532 -Test loss: 15894.85 -Diff -10819.682 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184 - Train loss: 26539.715 -Test loss: 15757.32 -Diff -10782.395 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.293\n",
      "Epoch 185 - Train loss: 26390.91 -Test loss: 15623.212 -Diff -10767.698 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.294\n",
      "Epoch 186 - Train loss: 26206.202 -Test loss: 15508.784 -Diff -10697.418 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.294\n",
      "Epoch 187 - Train loss: 26044.726 -Test loss: 15376.631 -Diff -10668.095 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.295\n",
      "Epoch 188 - Train loss: 25869.926 -Test loss: 15275.584 -Diff -10594.342 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.295\n",
      "Epoch 189 - Train loss: 25736.872 -Test loss: 15160.496 -Diff -10576.376 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.296\n",
      "Epoch 190 - Train loss: 25596.193 -Test loss: 15040.207 -Diff -10555.986 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.296\n",
      "Epoch 191 - Train loss: 25397.724 -Test loss: 14959.348 -Diff -10438.376 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.297\n",
      "Epoch 192 - Train loss: 25243.511 -Test loss: 14848.94 -Diff -10394.571 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.297\n",
      "Epoch 193 - Train loss: 25153.913 -Test loss: 14739.616 -Diff -10414.297 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.298\n",
      "Epoch 194 - Train loss: 24989.903 -Test loss: 14655.867 -Diff -10334.036 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.298\n",
      "Epoch 195 - Train loss: 24847.568 -Test loss: 14573.331 -Diff -10274.237 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.299\n",
      "Epoch 196 - Train loss: 24786.638 -Test loss: 14461.589 -Diff -10325.049 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.299\n",
      "Epoch 197 - Train loss: 24610.201 -Test loss: 14387.861 -Diff -10222.34 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.3\n",
      "Epoch 198 - Train loss: 24501.715 -Test loss: 14270.613 -Diff -10231.102 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.3\n",
      "Epoch 199 - Train loss: 24392.226 -Test loss: 14228.826 -Diff -10163.4 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.301\n",
      "Epoch 200 - Train loss: 24240.192 -Test loss: 14124.999 -Diff -10115.193 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.301\n",
      "Epoch 201 - Train loss: 24110.893 -Test loss: 14093.064 -Diff -10017.829 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.302\n",
      "Epoch 202 - Train loss: 23995.795 -Test loss: 14010.83 -Diff -9984.965 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.302\n",
      "Epoch 203 - Train loss: 23868.833 -Test loss: 13942.26 -Diff -9926.573 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.303\n",
      "Epoch 204 - Train loss: 23797.33 -Test loss: 13865.567 -Diff -9931.763 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.303\n",
      "Epoch 205 - Train loss: 23680.625 -Test loss: 13798.818 -Diff -9881.807 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.304\n",
      "Epoch 206 - Train loss: 23535.109 -Test loss: 13760.17 -Diff -9774.939 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.304\n",
      "Epoch 207 - Train loss: 23456.141 -Test loss: 13683.271 -Diff -9772.87 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.305\n",
      "Epoch 208 - Train loss: 23317.737 -Test loss: 13622.653 -Diff -9695.084 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.305\n",
      "Epoch 209 - Train loss: 23262.093 -Test loss: 13603.511 -Diff -9658.582 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.306\n",
      "Epoch 210 - Train loss: 23150.804 -Test loss: 13541.782 -Diff -9609.022 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.306\n",
      "Epoch 211 - Train loss: 23042.587 -Test loss: 13486.286 -Diff -9556.301 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.307\n",
      "Epoch 212 - Train loss: 22974.371 -Test loss: 13428.981 -Diff -9545.39 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.307\n",
      "Epoch 213 - Train loss: 22855.832 -Test loss: 13420.182 -Diff -9435.65 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.307\n",
      "Epoch 214 - Train loss: 22781.018 -Test loss: 13364.914 -Diff -9416.104 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.308\n",
      "Epoch 215 - Train loss: 22684.305 -Test loss: 13320.261 -Diff -9364.044 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.308\n",
      "Epoch 216 - Train loss: 22598.78 -Test loss: 13267.905 -Diff -9330.875 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.309\n",
      "Epoch 217 - Train loss: 22541.325 -Test loss: 13223.176 -Diff -9318.149 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.309\n",
      "Epoch 218 - Train loss: 22431.129 -Test loss: 13231.429 -Diff -9199.7 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.309\n",
      "Epoch 219 - Train loss: 22394.306 -Test loss: 13171.853 -Diff -9222.453 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.31\n",
      "Epoch 220 - Train loss: 22233.146 -Test loss: 13167.538 -Diff -9065.608 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.31\n",
      "Epoch 221 - Train loss: 22165.502 -Test loss: 13156.981 -Diff -9008.521 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.311\n",
      "Epoch 222 - Train loss: 22135.802 -Test loss: 13108.687 -Diff -9027.115 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.311\n",
      "Epoch 223 - Train loss: 22051.1 -Test loss: 13042.544 -Diff -9008.556 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.312\n",
      "Epoch 224 - Train loss: 21962.351 -Test loss: 13004.396 -Diff -8957.955 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.312\n",
      "Epoch 225 - Train loss: 21866.544 -Test loss: 12997.25 -Diff -8869.294 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.312\n",
      "Epoch 226 - Train loss: 21822.683 -Test loss: 12995.717 -Diff -8826.966 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.313\n",
      "Epoch 227 - Train loss: 21787.48 -Test loss: 12970.785 -Diff -8816.695 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.313\n",
      "Epoch 228 - Train loss: 21649.643 -Test loss: 12940.871 -Diff -8708.772 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.313\n",
      "Epoch 229 - Train loss: 21621.973 -Test loss: 12878.37 -Diff -8743.603 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.314\n",
      "Epoch 230 - Train loss: 21582.726 -Test loss: 12880.839 -Diff -8701.887 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.314\n",
      "Epoch 231 - Train loss: 21516.809 -Test loss: 12814.603 -Diff -8702.206 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.315\n",
      "Epoch 232 - Train loss: 21400.636 -Test loss: 12827.357 -Diff -8573.279 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.315\n",
      "Epoch 233 - Train loss: 21348.662 -Test loss: 12824.623 -Diff -8524.039 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.315\n",
      "Epoch 234 - Train loss: 21332.183 -Test loss: 12767.108 -Diff -8565.075 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.316\n",
      "Epoch 235 - Train loss: 21275.665 -Test loss: 12742.083 -Diff -8533.582 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.316\n",
      "Epoch 236 - Train loss: 21189.376 -Test loss: 12732.209 -Diff -8457.167 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.316\n",
      "Epoch 237 - Train loss: 21095.82 -Test loss: 12721.136 -Diff -8374.684 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.317\n",
      "Epoch 238 - Train loss: 21093.04 -Test loss: 12720.921 -Diff -8372.119 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.317\n",
      "Epoch 239 - Train loss: 21027.573 -Test loss: 12720.677 -Diff -8306.896 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.318\n",
      "Epoch 240 - Train loss: 20944.629 -Test loss: 12710.654 -Diff -8233.975 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.318\n",
      "Epoch 241 - Train loss: 20906.646 -Test loss: 12659.637 -Diff -8247.009 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.318\n",
      "Epoch 242 - Train loss: 20835.324 -Test loss: 12664.775 -Diff -8170.549 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.319\n",
      "Epoch 243 - Train loss: 20768.731 -Test loss: 12646.255 -Diff -8122.476 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.319\n",
      "Epoch 244 - Train loss: 20784.965 -Test loss: 12611.915 -Diff -8173.05 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245 - Train loss: 20672.914 -Test loss: 12615.983 -Diff -8056.931 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.32\n",
      "Epoch 246 - Train loss: 20629.115 -Test loss: 12592.382 -Diff -8036.733 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.32\n",
      "Epoch 247 - Train loss: 20557.148 -Test loss: 12598.036 -Diff -7959.112 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.32\n",
      "Epoch 248 - Train loss: 20563.804 -Test loss: 12606.964 -Diff -7956.84 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.321\n",
      "Epoch 249 - Train loss: 20475.428 -Test loss: 12546.189 -Diff -7929.239 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.321\n",
      "Epoch 250 - Train loss: 20452.768 -Test loss: 12526.01 -Diff -7926.758 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.321\n",
      "Epoch 251 - Train loss: 20405.81 -Test loss: 12513.063 -Diff -7892.747 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.322\n",
      "Epoch 252 - Train loss: 20319.238 -Test loss: 12504.707 -Diff -7814.531 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.322\n",
      "Epoch 253 - Train loss: 20266.566 -Test loss: 12530.821 -Diff -7735.745 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.322\n",
      "Epoch 254 - Train loss: 20240.052 -Test loss: 12491.094 -Diff -7748.958 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.322\n",
      "Epoch 255 - Train loss: 20222.405 -Test loss: 12504.698 -Diff -7717.707 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.323\n",
      "Epoch 256 - Train loss: 20175.417 -Test loss: 12486.949 -Diff -7688.468 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.323\n",
      "Epoch 257 - Train loss: 20104.022 -Test loss: 12490.622 -Diff -7613.4 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.323\n",
      "Epoch 258 - Train loss: 20042.109 -Test loss: 12472.243 -Diff -7569.866 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.324\n",
      "Epoch 259 - Train loss: 20034.589 -Test loss: 12450.909 -Diff -7583.68 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.324\n",
      "Epoch 260 - Train loss: 19987.421 -Test loss: 12475.499 -Diff -7511.922 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.324\n",
      "Epoch 261 - Train loss: 19983.253 -Test loss: 12441.786 -Diff -7541.467 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.325\n",
      "Epoch 262 - Train loss: 19960.666 -Test loss: 12407.295 -Diff -7553.371 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.325\n",
      "Epoch 263 - Train loss: 19889.996 -Test loss: 12405.26 -Diff -7484.736 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.325\n",
      "Epoch 264 - Train loss: 19841.305 -Test loss: 12399.053 -Diff -7442.252 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.326\n",
      "Epoch 265 - Train loss: 19812.95 -Test loss: 12418.555 -Diff -7394.395 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.326\n",
      "Epoch 266 - Train loss: 19764.971 -Test loss: 12381.295 -Diff -7383.676 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.326\n",
      "Epoch 267 - Train loss: 19735.089 -Test loss: 12382.049 -Diff -7353.04 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.326\n",
      "Epoch 268 - Train loss: 19675.824 -Test loss: 12393.261 -Diff -7282.563 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.327\n",
      "Epoch 269 - Train loss: 19664.272 -Test loss: 12387.858 -Diff -7276.414 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.327\n",
      "Epoch 270 - Train loss: 19592.586 -Test loss: 12397.769 -Diff -7194.817 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.327\n",
      "Epoch 271 - Train loss: 19571.262 -Test loss: 12450.742 -Diff -7120.52 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.328\n",
      "Epoch 272 - Train loss: 19570.11 -Test loss: 12440.228 -Diff -7129.882 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.328\n",
      "Epoch 273 - Train loss: 19536.417 -Test loss: 12412.591 -Diff -7123.826 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.328\n",
      "Epoch 274 - Train loss: 19492.22 -Test loss: 12404.595 -Diff -7087.625 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.328\n",
      "Epoch 275 - Train loss: 19445.363 -Test loss: 12400.201 -Diff -7045.162 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.329\n",
      "Epoch 276 - Train loss: 19417.678 -Test loss: 12361.927 -Diff -7055.751 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.329\n",
      "Epoch 277 - Train loss: 19402.854 -Test loss: 12398.423 -Diff -7004.431 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.329\n",
      "Epoch 278 - Train loss: 19368.853 -Test loss: 12377.978 -Diff -6990.875 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.33\n",
      "Epoch 279 - Train loss: 19305.824 -Test loss: 12391.019 -Diff -6914.805 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.33\n",
      "Epoch 280 - Train loss: 19308.66 -Test loss: 12374.562 -Diff -6934.098 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.33\n",
      "Epoch 281 - Train loss: 19247.138 -Test loss: 12364.208 -Diff -6882.93 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.33\n",
      "Epoch 282 - Train loss: 19186.5 -Test loss: 12360.827 -Diff -6825.673 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.331\n",
      "Epoch 283 - Train loss: 19176.619 -Test loss: 12352.933 -Diff -6823.686 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.331\n",
      "Epoch 284 - Train loss: 19145.047 -Test loss: 12350.493 -Diff -6794.554 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.331\n",
      "Epoch 285 - Train loss: 19096.54 -Test loss: 12367.588 -Diff -6728.952 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.331\n",
      "Epoch 286 - Train loss: 19164.61 -Test loss: 12351.041 -Diff -6813.569 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.332\n",
      "Epoch 287 - Train loss: 19099.586 -Test loss: 12365.955 -Diff -6733.631 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.332\n",
      "Epoch 288 - Train loss: 19025.825 -Test loss: 12341.46 -Diff -6684.365 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.332\n",
      "Epoch 289 - Train loss: 19043.953 -Test loss: 12357.223 -Diff -6686.73 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.332\n",
      "Epoch 290 - Train loss: 19022.606 -Test loss: 12323.292 -Diff -6699.314 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.333\n",
      "Epoch 291 - Train loss: 18965.14 -Test loss: 12317.023 -Diff -6648.117 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.333\n",
      "Epoch 292 - Train loss: 18914.177 -Test loss: 12361.575 -Diff -6552.602 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.333\n",
      "Epoch 293 - Train loss: 18906.093 -Test loss: 12337.915 -Diff -6568.178 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.333\n",
      "Epoch 294 - Train loss: 18881.814 -Test loss: 12327.264 -Diff -6554.55 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.334\n",
      "Epoch 295 - Train loss: 18884.028 -Test loss: 12322.127 -Diff -6561.901 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.334\n",
      "Epoch 296 - Train loss: 18838.855 -Test loss: 12291.197 -Diff -6547.658 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.334\n",
      "Epoch 297 - Train loss: 18802.072 -Test loss: 12278.893 -Diff -6523.179 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.334\n",
      "Epoch 298 - Train loss: 18758.921 -Test loss: 12304.093 -Diff -6454.828 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.335\n",
      "Epoch 299 - Train loss: 18783.353 -Test loss: 12293.459 -Diff -6489.894 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.335\n",
      "Epoch 300 - Train loss: 18774.997 -Test loss: 12268.257 -Diff -6506.74 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.335\n",
      "Epoch 301 - Train loss: 18722.051 -Test loss: 12245.786 -Diff -6476.265 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.335\n",
      "Epoch 302 - Train loss: 18704.494 -Test loss: 12247.665 -Diff -6456.829 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.336\n",
      "Epoch 303 - Train loss: 18666.911 -Test loss: 12271.535 -Diff -6395.376 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.336\n",
      "Epoch 304 - Train loss: 18658.019 -Test loss: 12228.237 -Diff -6429.782 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.336\n",
      "Epoch 305 - Train loss: 18609.447 -Test loss: 12237.602 -Diff -6371.845 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.336\n",
      "Epoch 306 - Train loss: 18576.829 -Test loss: 12226.602 -Diff -6350.227 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307 - Train loss: 18550.804 -Test loss: 12279.585 -Diff -6271.219 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.337\n",
      "Epoch 308 - Train loss: 18553.439 -Test loss: 12200.696 -Diff -6352.743 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.337\n",
      "Epoch 309 - Train loss: 18535.267 -Test loss: 12232.592 -Diff -6302.675 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.337\n",
      "Epoch 310 - Train loss: 18497.559 -Test loss: 12228.34 -Diff -6269.219 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.338\n",
      "Epoch 311 - Train loss: 18486.904 -Test loss: 12246.959 -Diff -6239.945 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.338\n",
      "Epoch 312 - Train loss: 18481.537 -Test loss: 12278.8 -Diff -6202.737 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.338\n",
      "Epoch 313 - Train loss: 18486.971 -Test loss: 12273.707 -Diff -6213.264 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.338\n",
      "Epoch 314 - Train loss: 18419.285 -Test loss: 12262.249 -Diff -6157.036 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.338\n",
      "Epoch 315 - Train loss: 18415.113 -Test loss: 12270.573 -Diff -6144.54 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.339\n",
      "Epoch 316 - Train loss: 18376.328 -Test loss: 12249.474 -Diff -6126.854 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.339\n",
      "Epoch 317 - Train loss: 18358.683 -Test loss: 12290.059 -Diff -6068.624 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.339\n",
      "Epoch 318 - Train loss: 18378.443 -Test loss: 12214.546 -Diff -6163.897 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.339\n",
      "Epoch 319 - Train loss: 18365.628 -Test loss: 12292.17 -Diff -6073.458 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.34\n",
      "Epoch 320 - Train loss: 18304.884 -Test loss: 12271.738 -Diff -6033.146 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.34\n",
      "Epoch 321 - Train loss: 18247.169 -Test loss: 12257.893 -Diff -5989.276 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.34\n",
      "Epoch 322 - Train loss: 18272.773 -Test loss: 12266.892 -Diff -6005.881 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.34\n",
      "Epoch 323 - Train loss: 18282.638 -Test loss: 12217.266 -Diff -6065.372 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.34\n",
      "Epoch 324 - Train loss: 18189.958 -Test loss: 12270.194 -Diff -5919.764 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.341\n",
      "Epoch 325 - Train loss: 18208.749 -Test loss: 12229.733 -Diff -5979.016 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.341\n",
      "Epoch 326 - Train loss: 18180.124 -Test loss: 12237.501 -Diff -5942.623 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.341\n",
      "Epoch 327 - Train loss: 18201.366 -Test loss: 12242.695 -Diff -5958.671 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.341\n",
      "Epoch 328 - Train loss: 18174.675 -Test loss: 12243.205 -Diff -5931.47 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.342\n",
      "Epoch 329 - Train loss: 18128.488 -Test loss: 12181.474 -Diff -5947.014 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.342\n",
      "Epoch 330 - Train loss: 18126.05 -Test loss: 12218.94 -Diff -5907.11 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.342\n",
      "Epoch 331 - Train loss: 18081.95 -Test loss: 12238.661 -Diff -5843.289 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.342\n",
      "Epoch 332 - Train loss: 18137.342 -Test loss: 12196.288 -Diff -5941.054 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.342\n",
      "Epoch 333 - Train loss: 18048.808 -Test loss: 12172.478 -Diff -5876.33 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.343\n",
      "Epoch 334 - Train loss: 18047.818 -Test loss: 12193.233 -Diff -5854.585 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.343\n",
      "Epoch 335 - Train loss: 17994.397 -Test loss: 12219.368 -Diff -5775.029 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.343\n",
      "Epoch 336 - Train loss: 18005.496 -Test loss: 12207.272 -Diff -5798.224 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.343\n",
      "Epoch 337 - Train loss: 18016.448 -Test loss: 12199.199 -Diff -5817.249 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.343\n",
      "Epoch 338 - Train loss: 17977.39 -Test loss: 12240.701 -Diff -5736.689 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.344\n",
      "Epoch 339 - Train loss: 17940.189 -Test loss: 12208.793 -Diff -5731.396 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.344\n",
      "Epoch 340 - Train loss: 17955.209 -Test loss: 12215.452 -Diff -5739.757 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.344\n",
      "Epoch 341 - Train loss: 17940.898 -Test loss: 12202.921 -Diff -5737.977 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.344\n",
      "Epoch 342 - Train loss: 17927.469 -Test loss: 12178.482 -Diff -5748.987 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.344\n",
      "Epoch 343 - Train loss: 17882.176 -Test loss: 12213.372 -Diff -5668.804 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.345\n",
      "Epoch 344 - Train loss: 17849.896 -Test loss: 12225.648 -Diff -5624.248 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.345\n",
      "Epoch 345 - Train loss: 17852.005 -Test loss: 12218.864 -Diff -5633.141 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.345\n",
      "Epoch 346 - Train loss: 17873.782 -Test loss: 12190.118 -Diff -5683.664 -Train FN 0.97 -Test FN 0.98 -Train MIoU 0.0 -Test MIou 0.345\n",
      "Epoch 347 - Train loss: 17865.644 -Test loss: 12225.592 -Diff -5640.052 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.345\n",
      "Epoch 348 - Train loss: 17812.567 -Test loss: 12243.98 -Diff -5568.587 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.346\n",
      "Epoch 349 - Train loss: 17814.085 -Test loss: 12263.857 -Diff -5550.228 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.346\n",
      "Epoch 350 - Train loss: 17783.586 -Test loss: 12239.11 -Diff -5544.476 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.346\n",
      "Epoch 351 - Train loss: 17757.496 -Test loss: 12258.155 -Diff -5499.341 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.346\n",
      "Epoch 352 - Train loss: 17720.94 -Test loss: 12251.775 -Diff -5469.165 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.346\n",
      "Epoch 353 - Train loss: 17778.455 -Test loss: 12225.608 -Diff -5552.847 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.346\n",
      "Epoch 354 - Train loss: 17723.274 -Test loss: 12280.845 -Diff -5442.429 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.347\n",
      "Epoch 355 - Train loss: 17681.925 -Test loss: 12314.692 -Diff -5367.233 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.347\n",
      "Epoch 356 - Train loss: 17701.985 -Test loss: 12273.747 -Diff -5428.238 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.347\n",
      "Epoch 357 - Train loss: 17692.439 -Test loss: 12280.952 -Diff -5411.487 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.347\n",
      "Epoch 358 - Train loss: 17632.782 -Test loss: 12281.801 -Diff -5350.981 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.347\n",
      "Epoch 359 - Train loss: 17617.21 -Test loss: 12299.683 -Diff -5317.527 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.348\n",
      "Epoch 360 - Train loss: 17633.416 -Test loss: 12335.729 -Diff -5297.687 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.348\n",
      "Epoch 361 - Train loss: 17622.651 -Test loss: 12364.886 -Diff -5257.765 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.348\n",
      "Epoch 362 - Train loss: 17573.536 -Test loss: 12409.153 -Diff -5164.383 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.348\n",
      "Epoch 363 - Train loss: 17551.818 -Test loss: 12401.753 -Diff -5150.065 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.348\n",
      "Epoch 364 - Train loss: 17579.133 -Test loss: 12407.064 -Diff -5172.069 -Train FN 0.97 -Test FN 0.979 -Train MIoU 0.0 -Test MIou 0.348\n",
      "Epoch 365 - Train loss: 17530.694 -Test loss: 12400.562 -Diff -5130.132 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.349\n",
      "Epoch 366 - Train loss: 17549.055 -Test loss: 12423.364 -Diff -5125.691 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.349\n",
      "Epoch 367 - Train loss: 17526.802 -Test loss: 12402.872 -Diff -5123.93 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.349\n",
      "Epoch 368 - Train loss: 17475.515 -Test loss: 12418.27 -Diff -5057.245 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369 - Train loss: 17437.176 -Test loss: 12392.101 -Diff -5045.075 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.349\n",
      "Epoch 370 - Train loss: 17457.777 -Test loss: 12390.712 -Diff -5067.065 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.349\n",
      "Epoch 371 - Train loss: 17428.848 -Test loss: 12423.5 -Diff -5005.348 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.35\n",
      "Epoch 372 - Train loss: 17437.523 -Test loss: 12468.61 -Diff -4968.913 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.35\n",
      "Epoch 373 - Train loss: 17407.6 -Test loss: 12429.809 -Diff -4977.791 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.35\n",
      "Epoch 374 - Train loss: 17406.971 -Test loss: 12425.437 -Diff -4981.534 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.35\n",
      "Epoch 375 - Train loss: 17390.714 -Test loss: 12414.545 -Diff -4976.169 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.35\n",
      "Epoch 376 - Train loss: 17414.858 -Test loss: 12400.957 -Diff -5013.901 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.35\n",
      "Epoch 377 - Train loss: 17374.146 -Test loss: 12444.575 -Diff -4929.571 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.351\n",
      "Epoch 378 - Train loss: 17357.357 -Test loss: 12463.092 -Diff -4894.265 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.351\n",
      "Epoch 379 - Train loss: 17368.882 -Test loss: 12428.14 -Diff -4940.742 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.351\n",
      "Epoch 380 - Train loss: 17378.499 -Test loss: 12475.251 -Diff -4903.248 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.351\n",
      "Epoch 381 - Train loss: 17322.152 -Test loss: 12449.473 -Diff -4872.679 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.351\n",
      "Epoch 382 - Train loss: 17311.907 -Test loss: 12488.313 -Diff -4823.594 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.351\n",
      "Epoch 383 - Train loss: 17272.737 -Test loss: 12435.936 -Diff -4836.801 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.352\n",
      "Epoch 384 - Train loss: 17310.553 -Test loss: 12489.211 -Diff -4821.342 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.352\n",
      "Epoch 385 - Train loss: 17284.369 -Test loss: 12516.594 -Diff -4767.775 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.352\n",
      "Epoch 386 - Train loss: 17267.076 -Test loss: 12515.508 -Diff -4751.568 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.352\n",
      "Epoch 387 - Train loss: 17249.796 -Test loss: 12511.012 -Diff -4738.784 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.352\n",
      "Epoch 388 - Train loss: 17263.675 -Test loss: 12504.846 -Diff -4758.829 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.352\n",
      "Epoch 389 - Train loss: 17223.649 -Test loss: 12520.609 -Diff -4703.04 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.353\n",
      "Epoch 390 - Train loss: 17232.01 -Test loss: 12513.084 -Diff -4718.926 -Train FN 0.97 -Test FN 0.978 -Train MIoU 0.0 -Test MIou 0.353\n",
      "Epoch 391 - Train loss: 17195.795 -Test loss: 12524.588 -Diff -4671.207 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.353\n",
      "Epoch 392 - Train loss: 17196.322 -Test loss: 12535.054 -Diff -4661.268 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.353\n",
      "Epoch 393 - Train loss: 17176.576 -Test loss: 12545.926 -Diff -4630.65 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.353\n",
      "Epoch 394 - Train loss: 17223.517 -Test loss: 12503.976 -Diff -4719.541 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.353\n",
      "Epoch 395 - Train loss: 17158.148 -Test loss: 12516.519 -Diff -4641.629 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.353\n",
      "Epoch 396 - Train loss: 17136.164 -Test loss: 12528.981 -Diff -4607.183 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.354\n",
      "Epoch 397 - Train loss: 17143.633 -Test loss: 12543.93 -Diff -4599.703 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.354\n",
      "Epoch 398 - Train loss: 17143.197 -Test loss: 12530.404 -Diff -4612.793 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.354\n",
      "Epoch 399 - Train loss: 17145.455 -Test loss: 12534.913 -Diff -4610.542 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.354\n",
      "Epoch 400 - Train loss: 17095.086 -Test loss: 12530.727 -Diff -4564.359 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.354\n",
      "Epoch 401 - Train loss: 17123.47 -Test loss: 12486.642 -Diff -4636.828 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.354\n",
      "Epoch 402 - Train loss: 17136.612 -Test loss: 12498.855 -Diff -4637.757 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.354\n",
      "Epoch 403 - Train loss: 17073.502 -Test loss: 12557.626 -Diff -4515.876 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.355\n",
      "Epoch 404 - Train loss: 17080.606 -Test loss: 12619.972 -Diff -4460.634 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.355\n",
      "Epoch 405 - Train loss: 17060.298 -Test loss: 12525.947 -Diff -4534.351 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.355\n",
      "Epoch 406 - Train loss: 17031.912 -Test loss: 12532.291 -Diff -4499.621 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.355\n",
      "Epoch 407 - Train loss: 17003.494 -Test loss: 12531.526 -Diff -4471.968 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.355\n",
      "Epoch 408 - Train loss: 17009.816 -Test loss: 12505.964 -Diff -4503.852 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.355\n",
      "Epoch 409 - Train loss: 17043.485 -Test loss: 12553.404 -Diff -4490.081 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.355\n",
      "Epoch 410 - Train loss: 16994.107 -Test loss: 12567.656 -Diff -4426.451 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.356\n",
      "Epoch 411 - Train loss: 16996.684 -Test loss: 12518.272 -Diff -4478.412 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.356\n",
      "Epoch 412 - Train loss: 17003.894 -Test loss: 12567.662 -Diff -4436.232 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.356\n",
      "Epoch 413 - Train loss: 16967.826 -Test loss: 12591.134 -Diff -4376.692 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.356\n",
      "Epoch 414 - Train loss: 16957.693 -Test loss: 12572.011 -Diff -4385.682 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.356\n",
      "Epoch 415 - Train loss: 16931.783 -Test loss: 12544.756 -Diff -4387.027 -Train FN 0.97 -Test FN 0.977 -Train MIoU 0.0 -Test MIou 0.356\n",
      "Epoch 416 - Train loss: 16931.564 -Test loss: 12574.923 -Diff -4356.641 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.356\n",
      "Epoch 417 - Train loss: 16945.131 -Test loss: 12586.625 -Diff -4358.506 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.356\n",
      "Epoch 418 - Train loss: 16935.976 -Test loss: 12528.997 -Diff -4406.979 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.357\n",
      "Epoch 419 - Train loss: 16905.554 -Test loss: 12566.251 -Diff -4339.303 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.357\n",
      "Epoch 420 - Train loss: 16918.299 -Test loss: 12542.484 -Diff -4375.815 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.357\n",
      "Epoch 421 - Train loss: 16884.834 -Test loss: 12589.091 -Diff -4295.743 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.357\n",
      "Epoch 422 - Train loss: 16915.861 -Test loss: 12548.361 -Diff -4367.5 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.357\n",
      "Epoch 423 - Train loss: 16911.262 -Test loss: 12613.782 -Diff -4297.48 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.357\n",
      "Epoch 424 - Train loss: 16841.281 -Test loss: 12568.495 -Diff -4272.786 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.357\n",
      "Epoch 425 - Train loss: 16845.981 -Test loss: 12558.587 -Diff -4287.394 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.357\n",
      "Epoch 426 - Train loss: 16875.454 -Test loss: 12561.77 -Diff -4313.684 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.358\n",
      "Epoch 427 - Train loss: 16855.322 -Test loss: 12585.801 -Diff -4269.521 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.358\n",
      "Epoch 428 - Train loss: 16817.743 -Test loss: 12572.055 -Diff -4245.688 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.358\n",
      "Epoch 429 - Train loss: 16838.388 -Test loss: 12561.339 -Diff -4277.049 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430 - Train loss: 16843.713 -Test loss: 12609.339 -Diff -4234.374 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.358\n",
      "Epoch 431 - Train loss: 16782.908 -Test loss: 12621.832 -Diff -4161.076 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.358\n",
      "Epoch 432 - Train loss: 16784.415 -Test loss: 12580.075 -Diff -4204.34 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.358\n",
      "Epoch 433 - Train loss: 16767.353 -Test loss: 12597.799 -Diff -4169.554 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.358\n",
      "Epoch 434 - Train loss: 16764.409 -Test loss: 12632.43 -Diff -4131.979 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.359\n",
      "Epoch 435 - Train loss: 16749.745 -Test loss: 12617.705 -Diff -4132.04 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.359\n",
      "Epoch 436 - Train loss: 16747.017 -Test loss: 12585.681 -Diff -4161.336 -Train FN 0.97 -Test FN 0.976 -Train MIoU 0.0 -Test MIou 0.359\n",
      "Epoch 437 - Train loss: 16746.644 -Test loss: 12607.332 -Diff -4139.312 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.359\n",
      "Epoch 438 - Train loss: 16736.921 -Test loss: 12621.696 -Diff -4115.225 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.359\n",
      "Epoch 439 - Train loss: 16701.115 -Test loss: 12610.97 -Diff -4090.145 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.359\n",
      "Epoch 440 - Train loss: 16765.616 -Test loss: 12603.877 -Diff -4161.739 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.359\n",
      "Epoch 441 - Train loss: 16718.577 -Test loss: 12591.358 -Diff -4127.219 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.359\n",
      "Epoch 442 - Train loss: 16708.212 -Test loss: 12612.316 -Diff -4095.896 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.36\n",
      "Epoch 443 - Train loss: 16704.444 -Test loss: 12636.574 -Diff -4067.87 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.36\n",
      "Epoch 444 - Train loss: 16719.978 -Test loss: 12672.56 -Diff -4047.418 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.36\n",
      "Epoch 445 - Train loss: 16695.464 -Test loss: 12632.827 -Diff -4062.637 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.36\n",
      "Epoch 446 - Train loss: 16683.015 -Test loss: 12636.388 -Diff -4046.627 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.36\n",
      "Epoch 447 - Train loss: 16691.031 -Test loss: 12651.639 -Diff -4039.392 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.36\n",
      "Epoch 448 - Train loss: 16687.49 -Test loss: 12634.852 -Diff -4052.638 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.36\n",
      "Epoch 449 - Train loss: 16660.091 -Test loss: 12667.354 -Diff -3992.737 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.36\n",
      "Epoch 450 - Train loss: 16670.748 -Test loss: 12685.138 -Diff -3985.61 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.36\n",
      "Epoch 451 - Train loss: 16659.09 -Test loss: 12625.973 -Diff -4033.117 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.361\n",
      "Epoch 452 - Train loss: 16657.234 -Test loss: 12623.808 -Diff -4033.426 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.361\n",
      "Epoch 453 - Train loss: 16592.232 -Test loss: 12653.837 -Diff -3938.395 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.361\n",
      "Epoch 454 - Train loss: 16617.079 -Test loss: 12634.455 -Diff -3982.624 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.361\n",
      "Epoch 455 - Train loss: 16576.314 -Test loss: 12609.622 -Diff -3966.692 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.361\n",
      "Epoch 456 - Train loss: 16565.086 -Test loss: 12656.301 -Diff -3908.785 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.361\n",
      "Epoch 457 - Train loss: 16563.25 -Test loss: 12636.61 -Diff -3926.64 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.361\n",
      "Epoch 458 - Train loss: 16592.046 -Test loss: 12637.326 -Diff -3954.72 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.361\n",
      "Epoch 459 - Train loss: 16551.818 -Test loss: 12668.083 -Diff -3883.735 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.361\n",
      "Epoch 460 - Train loss: 16588.863 -Test loss: 12648.326 -Diff -3940.537 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.362\n",
      "Epoch 461 - Train loss: 16583.72 -Test loss: 12617.742 -Diff -3965.978 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.362\n",
      "Epoch 462 - Train loss: 16535.63 -Test loss: 12629.864 -Diff -3905.766 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.362\n",
      "Epoch 463 - Train loss: 16511.873 -Test loss: 12682.432 -Diff -3829.441 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.362\n",
      "Epoch 464 - Train loss: 16534.363 -Test loss: 12643.815 -Diff -3890.548 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.362\n",
      "Epoch 465 - Train loss: 16492.657 -Test loss: 12628.116 -Diff -3864.541 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.362\n",
      "Epoch 466 - Train loss: 16555.209 -Test loss: 12625.727 -Diff -3929.482 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.362\n",
      "Epoch 467 - Train loss: 16512.903 -Test loss: 12623.629 -Diff -3889.274 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.362\n",
      "Epoch 468 - Train loss: 16527.049 -Test loss: 12616.917 -Diff -3910.132 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.362\n",
      "Epoch 469 - Train loss: 16499.631 -Test loss: 12617.769 -Diff -3881.862 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.362\n",
      "Epoch 470 - Train loss: 16507.874 -Test loss: 12625.117 -Diff -3882.757 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.363\n",
      "Epoch 471 - Train loss: 16478.253 -Test loss: 12625.272 -Diff -3852.981 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.363\n",
      "Epoch 472 - Train loss: 16467.629 -Test loss: 12574.233 -Diff -3893.396 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.363\n",
      "Epoch 473 - Train loss: 16501.132 -Test loss: 12584.851 -Diff -3916.281 -Train FN 0.97 -Test FN 0.975 -Train MIoU 0.0 -Test MIou 0.363\n",
      "Epoch 474 - Train loss: 16456.395 -Test loss: 12624.05 -Diff -3832.345 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.363\n",
      "Epoch 475 - Train loss: 16478.492 -Test loss: 12663.017 -Diff -3815.475 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.363\n",
      "Epoch 476 - Train loss: 16461.987 -Test loss: 12658.994 -Diff -3802.993 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.363\n",
      "Epoch 477 - Train loss: 16439.978 -Test loss: 12670.711 -Diff -3769.267 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.363\n",
      "Epoch 478 - Train loss: 16428.031 -Test loss: 12668.734 -Diff -3759.297 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.363\n",
      "Epoch 479 - Train loss: 16394.094 -Test loss: 12624.889 -Diff -3769.205 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.363\n",
      "Epoch 480 - Train loss: 16439.315 -Test loss: 12645.089 -Diff -3794.226 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n",
      "Epoch 481 - Train loss: 16402.79 -Test loss: 12661.197 -Diff -3741.593 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n",
      "Epoch 482 - Train loss: 16375.938 -Test loss: 12649.251 -Diff -3726.687 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n",
      "Epoch 483 - Train loss: 16388.795 -Test loss: 12610.607 -Diff -3778.188 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n",
      "Epoch 484 - Train loss: 16415.006 -Test loss: 12614.625 -Diff -3800.381 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n",
      "Epoch 485 - Train loss: 16375.962 -Test loss: 12617.444 -Diff -3758.518 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n",
      "Epoch 486 - Train loss: 16365.459 -Test loss: 12665.799 -Diff -3699.66 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n",
      "Epoch 487 - Train loss: 16404.782 -Test loss: 12628.31 -Diff -3776.472 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n",
      "Epoch 488 - Train loss: 16360.532 -Test loss: 12654.402 -Diff -3706.13 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n",
      "Epoch 489 - Train loss: 16368.389 -Test loss: 12640.645 -Diff -3727.744 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n",
      "Epoch 490 - Train loss: 16345.919 -Test loss: 12627.974 -Diff -3717.945 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491 - Train loss: 16340.336 -Test loss: 12618.512 -Diff -3721.824 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 492 - Train loss: 16378.314 -Test loss: 12637.254 -Diff -3741.06 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 493 - Train loss: 16342.114 -Test loss: 12627.835 -Diff -3714.279 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 494 - Train loss: 16306.821 -Test loss: 12619.519 -Diff -3687.302 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 495 - Train loss: 16329.589 -Test loss: 12660.809 -Diff -3668.78 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 496 - Train loss: 16338.133 -Test loss: 12643.687 -Diff -3694.446 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 497 - Train loss: 16301.32 -Test loss: 12656.567 -Diff -3644.753 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 498 - Train loss: 16300.754 -Test loss: 12612.436 -Diff -3688.318 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 499 - Train loss: 16274.761 -Test loss: 12645.116 -Diff -3629.645 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 500 - Train loss: 16290.012 -Test loss: 12627.046 -Diff -3662.966 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 501 - Train loss: 16240.725 -Test loss: 12648.599 -Diff -3592.126 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.365\n",
      "Epoch 502 - Train loss: 16248.618 -Test loss: 12615.06 -Diff -3633.558 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 503 - Train loss: 16272.921 -Test loss: 12592.824 -Diff -3680.097 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 504 - Train loss: 16256.377 -Test loss: 12584.521 -Diff -3671.856 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 505 - Train loss: 16221.137 -Test loss: 12655.386 -Diff -3565.751 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 506 - Train loss: 16248.695 -Test loss: 12607.166 -Diff -3641.529 -Train FN 0.97 -Test FN 0.974 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 507 - Train loss: 16287.431 -Test loss: 12652.652 -Diff -3634.779 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 508 - Train loss: 16237.743 -Test loss: 12644.48 -Diff -3593.263 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 509 - Train loss: 16182.298 -Test loss: 12715.354 -Diff -3466.944 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 510 - Train loss: 16239.675 -Test loss: 12668.858 -Diff -3570.817 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 511 - Train loss: 16203.328 -Test loss: 12676.881 -Diff -3526.447 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 512 - Train loss: 16229.338 -Test loss: 12665.238 -Diff -3564.1 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 513 - Train loss: 16145.619 -Test loss: 12677.43 -Diff -3468.189 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.366\n",
      "Epoch 514 - Train loss: 16210.934 -Test loss: 12614.673 -Diff -3596.261 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 515 - Train loss: 16189.413 -Test loss: 12653.82 -Diff -3535.593 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 516 - Train loss: 16189.742 -Test loss: 12632.747 -Diff -3556.995 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 517 - Train loss: 16189.401 -Test loss: 12698.951 -Diff -3490.45 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 518 - Train loss: 16220.526 -Test loss: 12664.357 -Diff -3556.169 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 519 - Train loss: 16174.503 -Test loss: 12634.076 -Diff -3540.427 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 520 - Train loss: 16161.098 -Test loss: 12689.528 -Diff -3471.57 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 521 - Train loss: 16129.573 -Test loss: 12634.747 -Diff -3494.826 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 522 - Train loss: 16142.36 -Test loss: 12611.557 -Diff -3530.803 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 523 - Train loss: 16156.843 -Test loss: 12621.909 -Diff -3534.934 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 524 - Train loss: 16136.719 -Test loss: 12649.202 -Diff -3487.517 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 525 - Train loss: 16139.168 -Test loss: 12691.783 -Diff -3447.385 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.367\n",
      "Epoch 526 - Train loss: 16133.183 -Test loss: 12650.213 -Diff -3482.97 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 527 - Train loss: 16099.863 -Test loss: 12614.132 -Diff -3485.731 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 528 - Train loss: 16100.019 -Test loss: 12671.998 -Diff -3428.021 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 529 - Train loss: 16090.034 -Test loss: 12668.167 -Diff -3421.867 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 530 - Train loss: 16116.585 -Test loss: 12646.941 -Diff -3469.644 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 531 - Train loss: 16082.263 -Test loss: 12658.316 -Diff -3423.947 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 532 - Train loss: 16111.531 -Test loss: 12666.435 -Diff -3445.096 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 533 - Train loss: 16083.229 -Test loss: 12665.004 -Diff -3418.225 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 534 - Train loss: 16094.131 -Test loss: 12697.334 -Diff -3396.797 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 535 - Train loss: 16058.081 -Test loss: 12678.563 -Diff -3379.518 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 536 - Train loss: 16082.478 -Test loss: 12637.975 -Diff -3444.503 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 537 - Train loss: 16085.834 -Test loss: 12683.291 -Diff -3402.543 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 538 - Train loss: 16077.21 -Test loss: 12633.435 -Diff -3443.775 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.368\n",
      "Epoch 539 - Train loss: 16096.015 -Test loss: 12690.898 -Diff -3405.117 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 540 - Train loss: 16021.093 -Test loss: 12672.608 -Diff -3348.485 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 541 - Train loss: 16032.137 -Test loss: 12663.735 -Diff -3368.402 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 542 - Train loss: 16027.438 -Test loss: 12684.677 -Diff -3342.761 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 543 - Train loss: 16039.105 -Test loss: 12707.384 -Diff -3331.721 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 544 - Train loss: 16037.929 -Test loss: 12719.427 -Diff -3318.502 -Train FN 0.97 -Test FN 0.972 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 545 - Train loss: 16030.397 -Test loss: 12677.189 -Diff -3353.208 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 546 - Train loss: 16028.407 -Test loss: 12647.958 -Diff -3380.449 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 547 - Train loss: 16027.207 -Test loss: 12648.411 -Diff -3378.796 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 548 - Train loss: 16007.532 -Test loss: 12723.324 -Diff -3284.208 -Train FN 0.97 -Test FN 0.972 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 549 - Train loss: 15997.032 -Test loss: 12658.859 -Diff -3338.173 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.369\n",
      "Epoch 550 - Train loss: 15989.907 -Test loss: 12638.978 -Diff -3350.929 -Train FN 0.97 -Test FN 0.973 -Train MIoU 0.0 -Test MIou 0.369\n"
     ]
    }
   ],
   "source": [
    "for e in range(550):\n",
    "    total_train_loss = 0.0\n",
    "    total_test_loss = 0.0\n",
    "    total_fn = 0.0\n",
    "    total_fnt = 0.0\n",
    "    total_miou = 0.0\n",
    "    total_miout = 0.0\n",
    "    test_loss = 0\n",
    "    test_IoU = 0\n",
    "    total_batch = 1*int(total_batch_train/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        #session2.run(running_vars_initializer)\n",
    "        train_x, train_y = session2.run([train_images, train_labels])\n",
    "        test_x, test_y = session2.run([eval_images, eval_labels])\n",
    "        #_, train_loss = session2.run([training_step, loss], feed_dict={input_images: train_x, input_labels: train_y})\n",
    "        #_ = session2.run([], feed_dict={input_images: train_x, input_labels: train_y, \n",
    "        #                                             phase:'True', keep_prob:'0.35'})\n",
    "        _, train_loss,acc = session2.run([training_step, loss,accuracy], feed_dict={input_images: train_x, \n",
    "                                                               input_labels: train_y, phase:'True', eval_phase:False,\n",
    "                                                                keep_prob:'0.50'})\n",
    "        #if i % 10 ==0:\n",
    "        _, test_loss, acc1= session2.run([predictionsOut, loss, accuracy], feed_dict={input_images: test_x, \n",
    "                                                                              input_labels: test_y, eval_phase:False,\n",
    "                                                              phase:'False', keep_prob:'1.0'})\n",
    "        #session2.run([mIoUop], feed_dict={input_images: test_x, input_labels: test_y, phase:'False', keep_prob:'1.0'})\n",
    "        total_train_loss += train_loss\n",
    "        total_test_loss += test_loss\n",
    "        total_fn +=acc\n",
    "        total_fnt +=acc1\n",
    "        miout = session2.run([MIoU], feed_dict={input_images: test_x, input_labels: test_y, \n",
    "                                                              phase:'False', keep_prob:'1.0'}) \n",
    "        \n",
    "        total_miout +=miout[0]\n",
    "        total_miou +=0\n",
    "        #print('batch {} - Train loss: {} - Test loss: {} - Test FN {}'.format(i+1,fn, test_loss, fnt)) - TrainRatio {} -TestRatio {}\n",
    "    print('Epoch {} - Train loss: {} -Test loss: {} -Diff {} -Train FN {} -Test FN {} -Train MIoU {} -Test MIou {}'.format(e+1, np.round(total_train_loss/total_batch,3), np.round(total_test_loss/total_batch,3),\n",
    "                 np.round(total_test_loss/total_batch,3) - np.round(total_train_loss/total_batch,3),\n",
    "                 np.round(total_fn/total_batch,2), np.round(total_fnt/total_batch,3), \n",
    "                 np.round(total_miou/total_batch,3), np.round(total_miout/total_batch,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Documents/AirNoAirTF/TFSelectedSing_12_3Classes'"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(session2, 'Documents/AirNoAirTF/TFSelectedSing_12_3Classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3385</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual      0.0   1.0  2.0\n",
       "prediction                \n",
       "0            27    23   16\n",
       "1             3  3385    2"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_images1, labels = get_batches_fn(1, parsedlisttrainSing['filepath'][955:956], x, y, z, True, varsM, 'Test','sing', True, datasettype='ds')\n",
    "test_x = session2.run(eval_images1)\n",
    "#test_x1 = tf.reshape(test_x,[-1,x,y,z,len(varsM)])\n",
    "pred1 = session2.run(predictionsOut, feed_dict={input_images: test_x, eval_phase:True,\n",
    "                                                              phase:'False', keep_prob:'1.0'})\n",
    "labels1 = np.reshape(labels.eval(),12*24*12)\n",
    "manual_eval = pd.DataFrame({'prediction':pred1[0],'actual':labels1})\n",
    "pd.crosstab(manual_eval.prediction, manual_eval.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/storage/opt/dsc/dse/sing/release/3.4.19/output/contraband_tagging_30cm_refit/output/run/8/600/0016/ContrabandFeatures_0_1_120.csv'"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedlisttrainSing['filepath'][651]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['rgb(0,0,255)', 'rgb(0,0,0)','rgb(0,0,255)', 'rgb(0,255,0)', 'rgb(0,128,255)', 'rgb(255,0,255)'\n",
    "          , 'rgb(255,255,51)', 'rgb(255,229,209)', 'rgb(0,255,255)']\n",
    "opacity_s = ['1','0.01','1','1','1','1','1','1','1']\n",
    "data = []\n",
    "plot_var = 'PredictedAir'\n",
    "dfA=dfA.sort_values(by=['x','y','z'])\n",
    "for i in range(len(dfA[plot_var].unique())):\n",
    "    name = np.sort(dfA[plot_var].unique())[i]\n",
    "    color = colors[i]\n",
    "    opacity = opacity_s[i]\n",
    "    x = dfA[ dfA[plot_var] == name ]['x']\n",
    "    y = dfA[ dfA[plot_var] == name ]['y']\n",
    "    z = dfA[ dfA[plot_var] == name ]['z']\n",
    "    \n",
    "    trace = dict(\n",
    "        name = name,\n",
    "        x = x, y = y, z = z,\n",
    "        type = \"scatter3d\",    \n",
    "        mode = 'markers',\n",
    "        marker = dict( size=5, color=color, line=dict(width=0), opacity=opacity ) )\n",
    "    data.append( trace )\n",
    "    \n",
    "layout = go.Layout(\n",
    "    title='dfB[[Int1,Int3,Int2,Int4]]'\n",
    ")\n",
    "\n",
    "#plotly.offline.plot([trace, layout])\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.plot(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_8:0' shape=(1, 12, 24, 12, 8) dtype=float32>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_images1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
